{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from io import BytesIO\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "dataset_path = './dataset/'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "else:\n",
    "    print(f\"The folder '{dataset_path}' already exists.\")\n",
    "\n",
    "with open(\"logs.txt\", \"a\") as logs_file:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(url, file_name, dataset_path):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36 Edge/112.0.1722.64',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if 'favicon.ico' not in url:\n",
    "                with open(\"logs.txt\", \"a\") as logs_file:\n",
    "                    logs_file.write(f\"Error accessing {url}: {e}\\n\")\n",
    "            return None\n",
    "\n",
    "        content_type = response.headers.get('Content-Type', '')\n",
    "        valid_types = ['image/png', 'image/jpeg', 'image/jpg', 'image/webp', 'image/gif', 'image/x-icon', 'image/vnd.microsoft.icon']\n",
    "        if content_type not in valid_types:\n",
    "            return None\n",
    "\n",
    "        image_data = BytesIO(response.content)\n",
    "        try:\n",
    "            image = Image.open(image_data)\n",
    "            image.verify()\n",
    "            image = Image.open(image_data)\n",
    "        except UnidentifiedImageError:\n",
    "            return None\n",
    "\n",
    "        width, height = image.size\n",
    "        if width > 512 or height > 512:\n",
    "            return None\n",
    "\n",
    "        image = image.convert(\"RGBA\")\n",
    "        file_path = os.path.join(dataset_path, file_name + \".png\")\n",
    "        image.save(file_path, format=\"PNG\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with open(\"logs.txt\", \"a\") as logs_file:\n",
    "            logs_file.write(f\"Error downloading the image from {url}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logo_from_html(domain):\n",
    "    response = None\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.5615.49 Safari/537.36 Edge/112.0.1722.64',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept': 'image/x-icon, image/*;q=0.8, */*;q=0.5'\n",
    "        }\n",
    "\n",
    "        urls = [\n",
    "            f'https://www.{domain}',\n",
    "            f'http://www.{domain}',\n",
    "            f'https://{domain}',\n",
    "            f'http://{domain}'\n",
    "        ]\n",
    "\n",
    "        correctUrl = ''\n",
    "        for url in urls:\n",
    "            headers['Referer'] = url\n",
    "            response = requests.get(url, verify=False, headers=headers, timeout=10)\n",
    "                    \n",
    "            if response.status_code == 403:\n",
    "                correctUrl = url\n",
    "                break\n",
    "\n",
    "            response.raise_for_status()\n",
    "            correctUrl = url\n",
    "            break\n",
    "\n",
    "        if response is None:\n",
    "            with open(\"logs.txt\", \"a\") as logs_file:\n",
    "                logs_file.write(f\"All requests failed for {domain}\\n\")\n",
    "            return None, []\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            found_images = []\n",
    "            images = soup.find_all('img')\n",
    "            for image in images:\n",
    "                image_url = image.get('src')\n",
    "                alt_text = image.get('alt', '').lower()\n",
    "                file_name = os.path.basename(image_url) if image_url else ''\n",
    "\n",
    "                if image.find_parent('header') and (\n",
    "                    'logo' in alt_text or \n",
    "                    'logo' in file_name.lower() or \n",
    "                    'favicon' in file_name.lower()\n",
    "                ):\n",
    "                    found_images.append(image_url)\n",
    "\n",
    "            link_tags = soup.find_all('link', rel='icon') + soup.find_all('link', rel='shortcut icon')\n",
    "            for link in link_tags:\n",
    "                found_images.append(link.get('href'))\n",
    "            \n",
    "            found_images.append('/favicon.ico')\n",
    "            \n",
    "            found_images = list(set(filter(None, found_images)))\n",
    "            return correctUrl, found_images\n",
    "        \n",
    "        except Exception as e:\n",
    "            with open(\"logs.txt\", \"a\") as logs_file:\n",
    "                logs_file.write(f\"Parsing error for {domain}: {e}\\n\")\n",
    "            return None, []\n",
    "    except Exception as e:\n",
    "        with open(\"logs.txt\", \"a\") as logs_file:\n",
    "            logs_file.write(f\"Error processing domain {domain}: {e}\\n\")\n",
    "        return None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(current, total, last_displayed_progress):\n",
    "    progress = (current + 1) / total * 100\n",
    "    progress = (progress // 10) * 10\n",
    "\n",
    "    if progress >= last_displayed_progress + 10:\n",
    "        print(f\"Progress: {progress}% ({current + 1}/{total})\")\n",
    "        return progress\n",
    "    \n",
    "    return last_displayed_progress\n",
    "\n",
    "def scrape_from_domains(domains):\n",
    "    size = len(domains)\n",
    "    last_progress = -1\n",
    "\n",
    "    for i, domain in enumerate(domains):\n",
    "        file_name = domain + '_' + str(i)\n",
    "\n",
    "        last_progress = show_progress(i, size, last_progress)\n",
    "\n",
    "        try:\n",
    "            url, logo_urls = get_logo_from_html(domain)\n",
    "            \n",
    "            for j, logo_url in enumerate(logo_urls):\n",
    "                logo_url = urljoin(url, logo_url)\n",
    "                save_image(logo_url, f\"{file_name}_{j}\", dataset_path)\n",
    "        except Exception as e:\n",
    "            with open(\"logs.txt\", \"a\") as logs_file:\n",
    "                logs_file.write(f\"Error processing domain {domain}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"logos.snappy.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "domains = df['domain']\n",
    "\n",
    "scrape_from_domains(domains)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
